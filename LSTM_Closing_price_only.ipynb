{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-Closing price only",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNpyo/0j+o9PGdsZHHZmuLN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vnaticzhock/Bank-Fraud-Detector/blob/main/LSTM_Closing_price_only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install statsmodels --upgrade\n",
        "# !pip install pmdarima\n",
        "!pip install arch"
      ],
      "metadata": {
        "id": "DJMPJBiRqDBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5IxBsuMGWz8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "from statsmodels.stats.diagnostic import het_arch\n",
        "import statsmodels.graphics.tsaplots as sgt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def timeFormat(time: str) -> str:\n",
        "  tmp = time.split('/')\n",
        "  tmp[0] = str(int(tmp[0]) + 1911)\n",
        "  return '-'.join(tmp)\n",
        "\n",
        "df = pd.read_csv('/content/æ—¥æ”¶ç›¤åƒ¹åŠæˆäº¤é‡ç­‰.csv')\n",
        "df['Unnamed: 0'] = df['Unnamed: 0'].apply(lambda x: timeFormat(x))\n",
        "df.index = pd.Index(df['Unnamed: 0'].copy())\n",
        "df = df.sort_index()\n",
        "dta = pd.concat([df['Close-Price'].pct_change() * 100, df['Close-Price']], axis=1).dropna()\n",
        "dta.columns = ['æ—¥å ±é…¬çŽ‡(%)', 'æ”¶ç›¤åƒ¹']\n",
        "dta.index.name = 'å¹´æœˆæ—¥'\n",
        "\n",
        "print(len(dta))\n",
        "dta.tail(3)"
      ],
      "metadata": {
        "id": "DDQEq5yOXY9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_p_value = adfuller(dta['æ—¥å ±é…¬çŽ‡(%)'])[1]\n",
        "print(price_p_value)\n",
        "if price_p_value > 0.05:\n",
        "    print('Nonstationary')\n",
        "else:\n",
        "    print('Stationary')"
      ],
      "metadata": {
        "id": "dy7Lqi6Uch9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "roi = dta['æ—¥å ±é…¬çŽ‡(%)'].values"
      ],
      "metadata": {
        "id": "vLJCqv5eXlTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class StockDataset(Dataset):\n",
        "  def __init__(self, x, df, mode='train'):\n",
        "    self.mode = mode\n",
        "\n",
        "    length = int(len(x) / 10 * 9)\n",
        "\n",
        "    if mode == 'train':\n",
        "      indices = [i for i in range(0, length)]\n",
        "    elif mode == 'dev':\n",
        "      indices = [i for i in range(length - 90, len(x))]\n",
        "    else: ## test\n",
        "      indices = [i for i in range(len(x))]\n",
        "\n",
        "    self.data = torch.FloatTensor(np.array(x).astype(float)[indices])\n",
        "    self.dataframe = df.iloc[indices]\n",
        "\n",
        "    self.target = []\n",
        "    for i in range(90, len(self.data)):\n",
        "      self.target.append(self.data[i])\n",
        "\n",
        "    self.target = torch.FloatTensor(np.array(self.target).astype(float))\n",
        "\n",
        "    self.dim = self.data.shape[1]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      return torch.FloatTensor(self.data[index : index + 90]), torch.FloatTensor(self.target[index])\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.target)"
      ],
      "metadata": {
        "id": "WYkEQPijotbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x = scaler.fit_transform(close_price)\n",
        "x = roi.reshape(-1, 1)\n",
        "\n",
        "stockDataset = StockDataset(list(x), dta, 'train')\n",
        "train_set = DataLoader(\n",
        "        stockDataset, 32,\n",
        "        shuffle=False, drop_last=False,\n",
        "        num_workers=0, pin_memory=True) \n",
        "\n",
        "devDataset = StockDataset(list(x), dta, 'dev')\n",
        "dev_set = DataLoader(\n",
        "        devDataset, 32,\n",
        "        shuffle=False, drop_last=False,\n",
        "        num_workers=0, pin_memory=True)"
      ],
      "metadata": {
        "id": "-Hn0Gf6asLln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter \n",
        "\n",
        "print(len(stockDataset), len(devDataset))"
      ],
      "metadata": {
        "id": "-9pEMB0UbrOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class LSTM_Attention(nn.Module):\n",
        "  def __init__(self):\n",
        "\n",
        "    self.embedding_dim = stockDataset.dim\n",
        "    self.n_hidden = 16\n",
        "\n",
        "    super(LSTM_Attention, self).__init__()\n",
        "    self.query = torch.randn(self.n_hidden).to(device)\n",
        "    self.lstm = nn.LSTM(self.embedding_dim, self.n_hidden)\n",
        "    self.linear = nn.Linear(self.n_hidden, 32)\n",
        "    self.activation = nn.ReLU()\n",
        "    self.out = nn.Linear(32, 1)\n",
        "    self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "\n",
        "  def attention_net(self, lstm_output):\n",
        "\n",
        "    attn_weights = (lstm_output * self.query.view(1,1, self.n_hidden)).sum(2)\n",
        "    soft_attn_weights = F.softmax(attn_weights, 1)\n",
        "\n",
        "    context = (lstm_output * soft_attn_weights.view(-1, 90, 1)).sum(1)\n",
        "\n",
        "    return context, soft_attn_weights\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    :param X: [Batch size, å¤©æ•¸, ç‰¹å¾µæ•¸é‡]\n",
        "    '''\n",
        "    x = x.transpose(0, 1)\n",
        "    output, (final_hidden_state, final_cell_state) = self.lstm(x)\n",
        "    ## output: [20, 8, 10] = [å¤©æ•¸, batch_size, embedding]\n",
        "    output = output.transpose(0, 1)\n",
        "    final_hidden_state = final_hidden_state.transpose(0, 1)\n",
        "    final_cell_state = final_cell_state.transpose(0, 1)\n",
        "\n",
        "    attn_output, attention = self.attention_net(output)\n",
        "    \n",
        "    return self.out(self.activation(self.linear(self.dropout(attn_output)))), attention\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self):\n",
        "\n",
        "    embedding_dim = stockDataset.dim\n",
        "    n_hidden = 10\n",
        "\n",
        "    super(LSTM, self).__init__()\n",
        "    self.lstm = nn.LSTM(embedding_dim, n_hidden, num_layers=2)\n",
        "    self.linear = nn.Linear(n_hidden * 2, 32)\n",
        "    self.activation = nn.ReLU()\n",
        "    self.out = nn.Linear(32, 1)\n",
        "    self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "        self.dropout,\n",
        "        self.linear,\n",
        "        self.activation,\n",
        "        self.out,\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    :param X: [Batch size, å¤©æ•¸, ç‰¹å¾µæ•¸é‡]\n",
        "    '''\n",
        "    # print(x.size())\n",
        "    x = x.transpose(0, 1)\n",
        "    output, (final_hidden_state, final_cell_state) = self.lstm(x)\n",
        "    # print(final_hidden_state.size())\n",
        "\n",
        "    return self.net(torch.flatten(final_hidden_state.transpose(0, 1), start_dim=1)), 0\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "  def __init__(self):\n",
        "\n",
        "    embedding_dim = stockDataset.dim\n",
        "    n_hidden = 10\n",
        "\n",
        "    super(BiLSTM, self).__init__()\n",
        "    self.lstm = nn.LSTM(embedding_dim, n_hidden, bidirectional=True)\n",
        "    self.linear = nn.Linear(n_hidden * 2, 32)\n",
        "    self.activation = nn.ReLU()\n",
        "    self.out = nn.Linear(32, 1)\n",
        "    self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "        self.dropout,\n",
        "        self.linear,\n",
        "        self.activation,\n",
        "        self.out,\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    :param X: [Batch size, å¤©æ•¸, ç‰¹å¾µæ•¸é‡]\n",
        "    '''\n",
        "    x = x.transpose(0, 1)\n",
        "    output, (final_hidden_state, final_cell_state) = self.lstm(x)\n",
        "\n",
        "    return self.net(torch.flatten(final_hidden_state.transpose(0, 1), start_dim=1)), 0\n",
        "        \n",
        "\n",
        "model = BiLSTM().to(device)\n",
        "loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "5z6X7eWhNutz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "min_mse = 1000.\n",
        "for epoch in tqdm(range(300)):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  counter_tr = 0\n",
        "\n",
        "  for x, y in train_set:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    pred, attention = model(x)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    counter_tr += float(loss.cpu().detach()) * len(y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  ## validating\n",
        "\n",
        "  counter = 0\n",
        "\n",
        "  model.eval()\n",
        "  for x, y in dev_set:\n",
        "    with torch.no_grad():\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      pred, attention = model(x)\n",
        "      loss = loss_fn(pred, y)\n",
        "      \n",
        "      counter += float(loss.cpu().detach()) * len(y)\n",
        "\n",
        "  dev_mse = counter / len(devDataset)\n",
        "  train_mse = counter_tr / len(stockDataset)\n",
        "  if (epoch + 1) % 15 == 0:\n",
        "    print(f'\\n Epoch: {epoch+1},\\n dev_loss: {dev_mse},\\n train_loss: {train_mse}')\n",
        "    # print(attention)\n",
        "\n",
        "  if epoch > 120 and dev_mse < min_mse:\n",
        "    # Save model if your model improved\n",
        "    min_mse = dev_mse\n",
        "    torch.save(model.state_dict(), './model.pth')\n",
        "    print(f'\\n Epoch: {epoch+1},\\n lowest now: {min_mse}')\n",
        "\n",
        "\n",
        "'''\n",
        "BiLSTM\n",
        "Epoch: 192,\n",
        "lowest now: 0.00011559145147629985\n",
        "\n",
        "Epoch: 282,\n",
        " lowest now: 9.559588342029005e-05\n",
        "\n",
        "LSTM stacked\n",
        "Epoch: 238,\n",
        "lowest now: 0.0001152252194570434\n",
        "\n",
        "Attention\n",
        "Epoch: 235,\n",
        "lowest now: 0.00011564536036916472\n",
        "'''"
      ],
      "metadata": {
        "id": "HFR4xTT-TI1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiLSTM().to(device)\n",
        "ckpt = torch.load('./model.pth', map_location='cpu')  # Load your best model\n",
        "model.load_state_dict(ckpt)\n",
        "\n",
        "x = roi.reshape(-1, 1)\n",
        "\n",
        "# totalDataset = StockDataset(list(x), df, 'total')\n",
        "# tt_set = DataLoader(\n",
        "#         totalDataset, 32,\n",
        "#         shuffle=False, drop_last=False,\n",
        "#         num_workers=0, pin_memory=True)\n",
        "\n",
        "truth = []\n",
        "preds = []\n",
        "\n",
        "for x, y in train_set:\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      pred, attention = model(x)\n",
        "\n",
        "      for i in range(len(y)):\n",
        "        truth.append(float(y[i].cpu().detach()))\n",
        "        preds.append(float(pred[i].cpu().detach()))\n",
        "\n",
        "residual = np.array(truth) - np.array(preds)\n",
        "\n",
        "truth = []\n",
        "preds = []\n",
        "\n",
        "for x, y in dev_set:\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      pred, attention = model(x)\n",
        "\n",
        "      for i in range(len(y)):\n",
        "        truth.append(float(y[i].cpu().detach()))\n",
        "        preds.append(float(pred[i].cpu().detach()))\n"
      ],
      "metadata": {
        "id": "LVCt6qX9hDmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(truth)\n",
        "print(devDataset.dataframe.iloc[90])\n",
        "## é æ¸¬çš„ç¬¬ä¸€å¤©æ˜¯å¾ž 2021-05-06 é–‹å§‹ï¼Œå¾ž2020-12-15é–‹å§‹æ‹¿90å¤©çš„è³‡æ–™é æ¸¬ä¸‹ä¸€å¤©"
      ],
      "metadata": {
        "id": "GQESh6y842d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(len(truth)), truth, label='Fact')\n",
        "plt.plot(range(len(preds)), preds, label='Predict')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GJkBfQMr2z7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "white_noise = acorr_ljungbox(residual, lags = [10], return_df=True)\n",
        "print(white_noise)\n",
        "\n",
        "LM_pvalue = het_arch(residual, ddof = 4)[1]\n",
        "print('LM-test-Pvalue:', '{:.5f}'.format(LM_pvalue))"
      ],
      "metadata": {
        "id": "UlmqfUhWN9Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize = (18,5))\n",
        "\n",
        "sgt.plot_acf(residual**2, zero = False, lags = 40, ax=ax[0])\n",
        "sgt.plot_pacf(residual**2, zero = False, lags = 40, ax=ax[1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q50g9JDnrBhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']\n",
        "\n",
        "date = devDataset.dataframe.index[-len(devDataset):]\n",
        "\n",
        "res = pd.DataFrame([truth, preds]).transpose()\n",
        "res.columns = ['æ—¥å ±é…¬çŽ‡(%)', 'LSTM ROI']\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "\n",
        "plt.plot(res['æ—¥å ±é…¬çŽ‡(%)'])\n",
        "plt.plot(res['LSTM ROI'])\n",
        "\n",
        "plt.legend(('Truth', 'LSTM'), fontsize=16)"
      ],
      "metadata": {
        "id": "0gYJuF4MyaN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(date)"
      ],
      "metadata": {
        "id": "z9SIF7pogdEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from arch import arch_model\n",
        "\n",
        "## æœ€é›£çš„åœ°æ–¹ï¼ðŸ˜­\n",
        "truth = []\n",
        "preds = []\n",
        "\n",
        "x = roi.reshape(-1, 1)\n",
        "\n",
        "totalDataset = StockDataset(list(x), dta, 'total')\n",
        "tt_set = DataLoader(\n",
        "        totalDataset, 32,\n",
        "        shuffle=False, drop_last=False,\n",
        "        num_workers=0, pin_memory=True)\n",
        "\n",
        "for x, y in tt_set:\n",
        "    with torch.no_grad():\n",
        "      model.eval()\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      pred, attention = model(x)\n",
        "\n",
        "      for i in range(len(y)):\n",
        "        truth.append(float(y[i].cpu().detach()))\n",
        "        preds.append(float(pred[i].cpu().detach()))\n",
        "\n",
        "residual = np.array(truth) - np.array(preds)\n",
        "\n",
        "garch_forecast = []\n",
        "for i in range(len(devDataset)):\n",
        "    # print(f'from 0 to {-(len(devDataset)-i)}')\n",
        "    train = residual[:-(len(devDataset)-i)]\n",
        "    model = arch_model(train, vol = 'GARCH', p = 1, q = 1)\n",
        "    garch_fit = model.fit()\n",
        "    prediction = garch_fit.forecast(horizon=1)\n",
        "    garch_forecast.append(np.sqrt(prediction.variance.values[-1:][0]))"
      ],
      "metadata": {
        "id": "jUUQ6jFSyiXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(res), len(garch_forecast))"
      ],
      "metadata": {
        "id": "kEQVzhOFxj7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## å¾—åˆ° test çš„æ—¥å ±é…¬çŽ‡(len=len(devDataset)); LSTM é æ¸¬çš„å ±é…¬çŽ‡\n",
        "res['GARCHé æ¸¬æ³¢å‹•åº¦'] = (garch_forecast)\n",
        "res['é æ¸¬å€é–“ä¸Šé™'] = res['LSTM ROI'] + res['GARCHé æ¸¬æ³¢å‹•åº¦']\n",
        "res['é æ¸¬å€é–“ä¸‹é™'] = res['LSTM ROI'] - res['GARCHé æ¸¬æ³¢å‹•åº¦']"
      ],
      "metadata": {
        "id": "mj9SbluCf1KA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_price = devDataset.dataframe['æ”¶ç›¤åƒ¹'][date[0]] / (1+res['æ—¥å ±é…¬çŽ‡(%)'][0]*0.01)\n",
        "print(date[0], devDataset.dataframe['æ”¶ç›¤åƒ¹'][date[0]], res['æ—¥å ±é…¬çŽ‡(%)'][0])"
      ],
      "metadata": {
        "id": "AloPDAiJyBBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# è¨ˆç®—ç¬¬ä¸€æœŸé æ¸¬\n",
        "res['LSTM é æ¸¬åƒ¹æ ¼'] = first_price * (1 + res['LSTM ROI']*0.01)\n",
        "res['é æ¸¬åƒ¹æ ¼å€é–“ä¸Šé™'] = first_price * (1 + res['é æ¸¬å€é–“ä¸Šé™']*0.01)\n",
        "res['é æ¸¬åƒ¹æ ¼å€é–“ä¸‹é™'] = first_price * (1 + res['é æ¸¬å€é–“ä¸‹é™']*0.01)\n",
        "\n",
        "# è¨ˆç®—å‰©é¤˜é æ¸¬å€é–“\n",
        "for i in range(1, len(res)):\n",
        "        res['LSTM é æ¸¬åƒ¹æ ¼'][i] = res['LSTM é æ¸¬åƒ¹æ ¼'][i-1] * (1 + res['LSTM ROI'][i]*0.01)\n",
        "        res['é æ¸¬åƒ¹æ ¼å€é–“ä¸Šé™'][i] = res['é æ¸¬åƒ¹æ ¼å€é–“ä¸Šé™'][i-1] * (1 + res['é æ¸¬å€é–“ä¸Šé™'][i]*0.01)\n",
        "        res['é æ¸¬åƒ¹æ ¼å€é–“ä¸‹é™'][i] = res['é æ¸¬åƒ¹æ ¼å€é–“ä¸‹é™'][i-1] * (1 + res['é æ¸¬å€é–“ä¸‹é™'][i]*0.01)\n",
        "# è¨ˆç®—å€é–“å‡åƒ¹\n",
        "res['é æ¸¬å¹³å‡åƒ¹æ ¼'] = (res['é æ¸¬åƒ¹æ ¼å€é–“ä¸Šé™'] + res['é æ¸¬åƒ¹æ ¼å€é–“ä¸‹é™']) / 2"
      ],
      "metadata": {
        "id": "dO-d8HG7h2Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res['æ”¶ç›¤åƒ¹'] = devDataset.dataframe['æ”¶ç›¤åƒ¹'][date].values"
      ],
      "metadata": {
        "id": "iZ42hasRzOaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "h3MkGQq7z6T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "\n",
        "plt.plot(res['æ”¶ç›¤åƒ¹'][:30], color = 'b')\n",
        "plt.plot(res['LSTM é æ¸¬åƒ¹æ ¼'][:30], color = 'r')\n",
        "plt.plot(res['é æ¸¬å¹³å‡åƒ¹æ ¼'][:30], color = 'r', linestyle='dashed')\n",
        "plt.plot(res['é æ¸¬åƒ¹æ ¼å€é–“ä¸Šé™'][:30], color = 'g')\n",
        "plt.plot(res['é æ¸¬åƒ¹æ ¼å€é–“ä¸‹é™'][:30], color = 'g')\n",
        "\n",
        "\n",
        "plt.legend(('Real', 'LSTM Anticipate', 'Mean', 'Upper bound', 'Downer bound'), fontsize=16)\n",
        "# plt.legend(('Real', 'LSTM Anticipate'), fontsize=16)"
      ],
      "metadata": {
        "id": "fod-a2sxzGT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "garch_std_resid = pd.Series(garch_fit.resid / garch_fit.conditional_volatility)\n",
        "white_noise_garch = acorr_ljungbox(garch_std_resid, lags = [10], return_df=True)\n",
        "white_noise_garch"
      ],
      "metadata": {
        "id": "D2ezoHnJrlbM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}